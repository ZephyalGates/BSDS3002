{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from requests import post, get\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials = [\n",
    "    # ('e0c69679b0b7452ba1e946c37ba6f764', 'efc8135d62554a0790c4b9dca7156bbc'),\n",
    "    # ('cdf75282fa8144dda8018c861f41a4c9', 'e7ef1fb2c0ab4d58a196e4f0b0f4fe70'),\n",
    "    ('31922bf702714f66b4294cbc16d17fb6', '0e321c8a15324df8a249b7cf2b52ec76'),\n",
    "    ('ab611466a20546d0b0e2e0b8bdfb87a3', '4fdcf84f415a4d37a718da6835e23082')\n",
    "    # ('b3d5770c1b824d3ebdc805290e9abc1f', '01609af484f94eab9b77f6a84c4ecbde'),\n",
    "    # ('4225b73cc1074094aaa695b5c9d5f610', '1ddb33f2f3d047ccae7e3bcc7df30c79'),\n",
    "    # ('206782e057b7465b899a5b4ae6feabff', '35b491b06101488aaf1c5735638e8307'),\n",
    "    # ('220266650ffb4ffc96c8cd3989c87f48', '5cc43b25e0454284b414362000edcd68'),\n",
    "    # ('03c5419a6a324213850690c1820d07cd', 'fb36dc81965b4ae39e0e81215cf12124'),\n",
    "    # ('afd9c9421cb84f17b45bfe0bc89c0cd1', '2d5ebf61ebe94ef2ab2f4e1cce02def8'),\n",
    "    # ('da2f148a6d3c4eec9c106106f1015a0b', 'e3da3906110e4b22963423c4f018af60'),\n",
    "    # ('7ce1ad74b969497d9a5c57489670d08f', 'd9907b42abbe4923bee2f7cfccf82946'),\n",
    "    # ('ed335709032445beb21a6abfe00b805e', '6a1c1310bbf3416aa1acf9cb1fc33ac3'),\n",
    "    # ('84be5714a8eb43289371bfea95054e2f', 'a4520f8a7ea24e47a9ccf5e911205b9f'),\n",
    "    # ('326b44ed8b20460590ac84d7422099f6', '33d0b014852343ab9ffcaaafcedd8347'),\n",
    "    # ('469e49ddbdb24c69bee3ab1be9b5eac1', 'dbb33a3d14194fb1af0064f5e19fe365'),\n",
    "    # ('1475e2c15aa048d68a48805e5bb0a70d', '906bb9f9e18c425f9f7d4b539f080b98'),\n",
    "    # ('6b61506f190e432ea639de97b81c2e23', '53be096902a746bf9cba27ea56f8059c'),\n",
    "    # ('f27bf844a9cb4d208ea119e0481955b1', 'd4b377287b31482dbe1f64062f9d1854'),\n",
    "    # ('74bb3ea8357a42c0a1b61af3f2ce1f81', '270ca3c440954d908fcd215ce2081b55'),\n",
    "    # ('a3be98d4ae3245d382adbb93b0e08828', '68c3a02702774e779356e9b843d7c0d8')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "credential_index = 0\n",
    "\n",
    "def get_token(client_id, client_secret):\n",
    "    auth_string = client_id + \":\" + client_secret\n",
    "    auth_bytes = auth_string.encode(\"utf-8\")\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes), \"utf-8\")\n",
    "\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Basic \" + auth_base64,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    json_result = json.loads(response.content)\n",
    "\n",
    "    if \"access_token\" in json_result:\n",
    "        token = json_result[\"access_token\"]\n",
    "        return token\n",
    "    else:\n",
    "        print(\"Error: Failed to get access token\")\n",
    "        print(json_result)\n",
    "        return None\n",
    "\n",
    "def get_auth_header(token):\n",
    "    return {\"Authorization\": \"Bearer \" + token}\n",
    "\n",
    "def get_albums_for_artist(token, artist_id):\n",
    "    url = f\"https://api.spotify.com/v1/artists/{artist_id}/albums\"\n",
    "    headers = get_auth_header(token)\n",
    "    params = {\"include_groups\": \"album\"}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        albums = json.loads(response.text)[\"items\"]\n",
    "        album_dict = {}\n",
    "        for album in albums:\n",
    "            album_id = album[\"id\"]\n",
    "            album_name = album[\"name\"]\n",
    "            album_tracks = album[\"total_tracks\"]\n",
    "            album_type = album[\"album_type\"]\n",
    "            album_release_date = album[\"release_date\"]\n",
    "            album_artists = [artist[\"name\"] for artist in album[\"artists\"]]\n",
    "            album_images = album[\"images\"]\n",
    "\n",
    "            if album_name in album_dict:\n",
    "                existing_tracks = album_dict[album_name][\"total_tracks\"]\n",
    "                if album_tracks > existing_tracks:\n",
    "                    album_dict[album_name] = {\n",
    "                        \"album_id\": album_id,\n",
    "                        \"album_name\": album_name,\n",
    "                        \"total_tracks\": album_tracks,\n",
    "                        \"album_type\": album_type,\n",
    "                        \"release_date\": album_release_date,\n",
    "                        \"artists\": album_artists,\n",
    "                        \"images\": album_images\n",
    "                    }\n",
    "            else:\n",
    "                album_dict[album_name] = {\n",
    "                    \"album_id\": album_id,\n",
    "                    \"album_name\": album_name,\n",
    "                    \"total_tracks\": album_tracks,\n",
    "                    \"album_type\": album_type,\n",
    "                    \"release_date\": album_release_date,\n",
    "                    \"artists\": album_artists,\n",
    "                    \"images\": album_images\n",
    "                }\n",
    "        return album_dict\n",
    "    else:\n",
    "        print(\"Error: Failed to get albums for artist\")\n",
    "        print(response.content)\n",
    "        return None\n",
    "    \n",
    "def get_tracks_for_album(token, album_id):\n",
    "    url = f\"https://api.spotify.com/v1/albums/{album_id}/tracks\"\n",
    "    headers = get_auth_header(token)\n",
    "    params = {\"market\": \"US\"}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        tracks = json.loads(response.text)[\"items\"]\n",
    "        track_list = []\n",
    "        for track in tracks:\n",
    "            track_name = track[\"name\"]\n",
    "            track_id = track[\"id\"]\n",
    "            track_number = track[\"track_number\"]\n",
    "            track_explicit = track[\"explicit\"]\n",
    "            track_artists = [artist[\"name\"] for artist in track[\"artists\"]]\n",
    "            track_dict = {\n",
    "                \"track_name\": track_name,\n",
    "                \"track_id\": track_id,\n",
    "                \"track_number\": track_number,\n",
    "                \"track_explicit\": track_explicit,\n",
    "                \"track_artists\": track_artists,\n",
    "            }\n",
    "            track_list.append(track_dict)\n",
    "        return track_list\n",
    "    else:\n",
    "        print(\"Error: Failed to get tracks for album\")\n",
    "        print(response.content)\n",
    "        return None\n",
    "\n",
    "# def get_audio_features(token, track_ids):\n",
    "#     headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "#     url = \"https://api.spotify.com/v1/audio-features\"\n",
    "    \n",
    "#     id_chunks = [track_ids[i:i+100] for i in range(0, len(track_ids), 100)]\n",
    "    \n",
    "#     dfs = []\n",
    "#     for chunk in id_chunks:\n",
    "#         params = {\"ids\": \",\".join(chunk)}\n",
    "#         response = requests.get(url, headers=headers, params=params)\n",
    "#         data = response.json()[\"audio_features\"]\n",
    "#         features = pd.DataFrame(data)\n",
    "#         features = features.drop([\"type\", \"uri\", \"track_href\", \"analysis_url\"], axis=1)\n",
    "#         dfs.append(features)\n",
    "    \n",
    "#     features = pd.concat(dfs, ignore_index=True)\n",
    "#     return features\n",
    "\n",
    "def get_audio_features(token, track_ids):\n",
    "    audio_features = []\n",
    "\n",
    "    for i in range(0, len(track_ids), 50):\n",
    "        chunk = track_ids[i:i + 50]\n",
    "        ids = ','.join(chunk)\n",
    "        url = f\"https://api.spotify.com/v1/audio-features?ids={ids}\"\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        r = requests.get(url, headers=headers)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Error getting audio features for tracks: {r.status_code}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            features = r.json()[\"audio_features\"]\n",
    "        except KeyError:\n",
    "            features = []\n",
    "\n",
    "        audio_features.extend(features)\n",
    "\n",
    "    audio_features_filtered = []\n",
    "    for feature in audio_features:\n",
    "        if feature is not None:\n",
    "            audio_features_filtered.append(feature)\n",
    "\n",
    "    return pd.DataFrame(audio_features_filtered)\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint():\n",
    "    if os.path.exists('checkpoint_1.json'):\n",
    "        with open('checkpoint_1.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {\"artist_id\": \"\", \"progress\": 0}\n",
    "\n",
    "def save_checkpoint(artist_id, progress):\n",
    "    with open('checkpoint_1.json', 'w') as f:\n",
    "        json.dump({\"artist_id\": artist_id, \"progress\": progress}, f)\n",
    "\n",
    "def load_failed_requests():\n",
    "    if os.path.exists('failed_requests_1.parquet'):\n",
    "        return pd.read_parquet('failed_requests_1.parquet')\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['Spotify ID'])\n",
    "\n",
    "def save_failed_requests(df):\n",
    "    df.to_parquet('failed_requests_1.parquet')\n",
    "\n",
    "def refresh_token(token_start_time):\n",
    "    global credential_index\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - token_start_time\n",
    "    if elapsed_time >= 1800:\n",
    "        credential_index = (credential_index + 1) % len(client_credentials)\n",
    "        client_id, client_secret = client_credentials[credential_index]\n",
    "        return get_token(client_id, client_secret), current_time\n",
    "    return None, token_start_time\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    return re.sub(r'[\\\\/:\"*?<>|]+', '_', filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('artist_ids_sub_dict_1.json', 'r') as f:\n",
    "    artist_ids = json.load(f)\n",
    "len(artist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Mystikal: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "Processing The Kinsey Report: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\n",
      "Processing Insane Clown Posse: 100%|██████████| 20/20 [00:21<00:00,  1.10s/it]\n",
      "Processing The Interpreters: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Processing Ron Levy: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "Processing Bananarama: 100%|██████████| 15/15 [00:16<00:00,  1.11s/it]\n",
      "Processing The Commitments: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]\n",
      "Processing Moloko: 100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n",
      "Processing Howie Day: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\n",
      "Processing H-Town: 100%|██████████| 9/9 [00:09<00:00,  1.10s/it]\n",
      "Processing Dalis Car: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Processing Prince Buster: 100%|██████████| 20/20 [00:22<00:00,  1.12s/it]\n",
      "Processing Sacrifice Isaac: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Processing John Fahey: 100%|██████████| 19/19 [00:21<00:00,  1.11s/it]\n",
      "Processing Carl Maria von Weber: 100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n",
      "Processing Steve Walsh: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n",
      "Processing Joe Ely: 100%|██████████| 19/19 [00:21<00:00,  1.13s/it]\n",
      "Processing Rio Reiser: 100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Processing Steve Martin: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "Processing Popincourt:   0%|          | 0/2 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21912\\3020825708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mall_tracks_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0malbum_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malbum_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'album_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Processing {artist_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mtracks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tracks_for_album\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malbum_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtracks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "token = get_token('7727b6a6602f4dcf99d337ee11f0983e', '6b4958253cb544aaae1b0bf4858726ee')\n",
    "token_start_time = time.time()\n",
    "\n",
    "checkpoint = load_checkpoint()\n",
    "failed_requests = load_failed_requests()\n",
    "\n",
    "start_from = checkpoint[\"artist_id\"] if checkpoint[\"artist_id\"] else list(artist_ids.keys())[0]\n",
    "start_index = list(artist_ids.keys()).index(start_from)\n",
    "\n",
    "\n",
    "iteration_counter = 0\n",
    "sleep_interval = 50\n",
    "\n",
    "for artist_id, artist_name in list(artist_ids.items())[start_index:]:\n",
    "    try:\n",
    "        refreshed_token, new_token_start_time = refresh_token(token_start_time)\n",
    "        if refreshed_token:\n",
    "            token = refreshed_token\n",
    "            token_start_time = new_token_start_time\n",
    "\n",
    "        albums = get_albums_for_artist(token, artist_id)\n",
    "\n",
    "        if albums is None:\n",
    "            failed_requests = failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "            save_failed_requests(failed_requests)\n",
    "            continue\n",
    "\n",
    "        album_df = pd.DataFrame.from_dict(albums, orient=\"index\")\n",
    "        album_df.index.name = \"album_name\"\n",
    "\n",
    "        all_tracks_df = pd.DataFrame()\n",
    "        for album_id in tqdm(album_df['album_id'], desc=f\"Processing {artist_name}\"):\n",
    "            time.sleep(1)\n",
    "            tracks = get_tracks_for_album(token, album_id)\n",
    "            if tracks is None:\n",
    "                failed_requests = failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "                save_failed_requests(failed_requests)\n",
    "                continue\n",
    "\n",
    "            tracks = pd.DataFrame(tracks)\n",
    "            tracks['album_id'] = album_id\n",
    "            all_tracks_df = pd.concat([all_tracks_df, tracks], axis=0)\n",
    "\n",
    "        af_df = get_audio_features(token, all_tracks_df['track_id'].tolist())\n",
    "        af_df = af_df.rename(columns={'id': 'track_id'})\n",
    "        all_aftracks_df = pd.merge(all_tracks_df, af_df, on='track_id')\n",
    "        album_all_aftracks_df = pd.merge(album_df, all_aftracks_df, on='album_id')\n",
    "        sanitized_artist_name = sanitize_filename(artist_name)\n",
    "        album_all_aftracks_df.to_parquet(f'results/{sanitized_artist_name}_tracks.parquet')\n",
    "\n",
    "        save_checkpoint(artist_id, artist_name)\n",
    "        iteration_counter += 1\n",
    "        if iteration_counter % sleep_interval == 0:\n",
    "            time.sleep(10)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {artist_name}: {e}\")\n",
    "        failed_requests = failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "        save_failed_requests(failed_requests)\n",
    "        continue\n",
    "\n",
    "print(\"Completed processing all artists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_retries = 3\n",
    "# retry_counter = 0\n",
    "\n",
    "# while not failed_requests.empty and retry_counter < max_retries:\n",
    "#     print(f\"Retrying failed requests (attempt {retry_counter + 1}/{max_retries})...\")\n",
    "#     retry_failed_requests = pd.DataFrame(columns=[\"Spotify ID\"])\n",
    "#     for _, row in failed_requests.iterrows():\n",
    "#         artist_id = row[\"Spotify ID\"]\n",
    "#         artist_name = artist_ids[artist_id]\n",
    "#         sanitized_artist_name = sanitize_filename(artist_name)\n",
    "#         parquet_file_path = f'{sanitized_artist_name}_tracks.parquet'\n",
    "\n",
    "#         if os.path.exists(parquet_file_path):\n",
    "#             print(f\"Parquet file already exists for {artist_name}, skipping...\")\n",
    "#             continue\n",
    "#         try:\n",
    "#             refreshed_token, new_token_start_time = refresh_token(token_start_time)\n",
    "#             if refreshed_token:\n",
    "#                 token = refreshed_token\n",
    "#                 token_start_time = new_token_start_time\n",
    "#             albums = get_albums_for_artist(token, artist_id)\n",
    "\n",
    "#             if albums is None:\n",
    "#                 failed_requests = failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "#                 save_failed_requests(failed_requests)\n",
    "#                 continue\n",
    "\n",
    "#             album_df = pd.DataFrame.from_dict(albums, orient=\"index\")\n",
    "#             album_df.index.name = \"album_name\"\n",
    "\n",
    "#             all_tracks_df = pd.DataFrame()\n",
    "#             for album_id in tqdm(album_df['album_id'], desc=f\"Processing {artist_name}\"):\n",
    "#                 time.sleep(1)\n",
    "#                 try:\n",
    "#                     tracks = get_tracks_for_album(token, album_id)\n",
    "\n",
    "#                     if tracks is None:\n",
    "#                         failed_requests = failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "#                         save_failed_requests(failed_requests)\n",
    "#                         continue\n",
    "\n",
    "#                     tracks = pd.DataFrame(tracks)\n",
    "#                     tracks['album_id'] = album_id\n",
    "#                     all_tracks_df = pd.concat([all_tracks_df, tracks], axis=0)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Warning: Error fetching tracks for {artist_name}: {e}\")\n",
    "\n",
    "#             try:\n",
    "#                 af_df = get_audio_features(token, all_tracks_df['track_id'].tolist())\n",
    "#                 af_df = af_df.rename(columns={'id': 'track_id'})\n",
    "#                 all_aftracks_df = pd.merge(all_tracks_df, af_df, on='track_id')\n",
    "#                 album_all_aftracks_df = pd.merge(album_df, all_aftracks_df, on='album_id')\n",
    "#                 sanitized_artist_name = sanitize_filename(artist_name)\n",
    "#                 album_all_aftracks_df.to_parquet(f'{sanitized_artist_name}_tracks.parquet')\n",
    "\n",
    "#                 save_checkpoint(artist_id, artist_name)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Warning: Error fetching audio features for {artist_name}: {e}\")\n",
    "\n",
    "#             iteration_counter += 1\n",
    "#             if iteration_counter % sleep_interval == 0:\n",
    "#                 time.sleep(1)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {artist_name}: {e}\")\n",
    "#             retry_failed_requests = retry_failed_requests.append({\"Spotify ID\": artist_id}, ignore_index=True)\n",
    "\n",
    "#     failed_requests = retry_failed_requests\n",
    "#     retry_counter += 1\n",
    "\n",
    "# if not failed_requests.empty:\n",
    "#     print(\"Some requests still failed after all retries:\")\n",
    "#     print(failed_requests)\n",
    "# else:\n",
    "#     print(\"All failed requests have been successfully processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
